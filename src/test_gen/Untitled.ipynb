{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import torch\n",
    "import torchaudio\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "class Functions:\n",
    "    def row_wise_f1_score_micro(self, y_true, y_pred):\n",
    "        F1 = []\n",
    "        for preds, trues in zip(y_pred, y_true):\n",
    "            TP, FN, FP = 0, 0, 0\n",
    "            preds = preds.split()\n",
    "            trues = trues.split()\n",
    "            for true in trues:\n",
    "                if true in preds:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FN += 1\n",
    "            for pred in preds:\n",
    "                if pred not in trues:\n",
    "                    FP += 1\n",
    "            F1.append(2 * TP / (2 * TP + FN + FP))\n",
    "        return np.mean(F1)\n",
    "\n",
    "    def boost_multiple_occurences(\n",
    "        self,\n",
    "        df,\n",
    "        labels,\n",
    "        pred_col,\n",
    "        out_col=\"y_pred\",\n",
    "        boost_coef=1.1,\n",
    "        max_boost_coef=12,\n",
    "        threshold=0.5,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Boost predictions in file:\n",
    "            - if something occured once, multiply that class by boost_coef\n",
    "            - if something occured more than once - keep multiplying until\n",
    "                boost_coef reaches max_boost_coef\n",
    "        \"\"\"\n",
    "\n",
    "        def _compute_boost_matrix(\n",
    "            y_preds, labels, threshold, boost_coef, max_boost_coef\n",
    "        ):\n",
    "            nocall_ix = labels.index(\"nocall\")\n",
    "            boost_matrix = np.ones((len(labels)), dtype=np.float64)\n",
    "            for p in y_preds:\n",
    "                boost_matrix = boost_matrix * np.where(p > threshold, boost_coef, 1.0)\n",
    "                boost_matrix = np.clip(boost_matrix, 1.0, max_boost_coef)\n",
    "                boost_matrix[nocall_ix] = 1.0\n",
    "            return boost_matrix\n",
    "\n",
    "        dict_pred = {}\n",
    "        for filename in set(df[\"filename\"]):  # type: ignore\n",
    "            file_df = df[df.filename == filename]\n",
    "            file_y_preds = file_df[pred_col].values\n",
    "            list_row_id = file_df[\"row_id\"].values\n",
    "            bm = _compute_boost_matrix(\n",
    "                file_y_preds,\n",
    "                labels=labels,\n",
    "                threshold=threshold,\n",
    "                boost_coef=boost_coef,\n",
    "                max_boost_coef=max_boost_coef,\n",
    "            )\n",
    "\n",
    "            file_y_preds = bm * file_y_preds\n",
    "            for i in range(len(list_row_id)):\n",
    "                dict_pred[list_row_id[i]] = file_y_preds[i]\n",
    "        return dict_pred\n",
    "\n",
    "\n",
    "class Mel_Provider:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fft,\n",
    "        win_length,\n",
    "        n_mels,\n",
    "        sample_rate,\n",
    "        mel_image_size,\n",
    "        min_frequency,\n",
    "        max_frequency,\n",
    "        signal_lenght,\n",
    "        hop_length=None,\n",
    "        norm_mel_long=False,\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        self.norm_mel_long = norm_mel_long\n",
    "        self._device = device\n",
    "        self.signal_lenght = signal_lenght\n",
    "        self.sample_rate = sample_rate\n",
    "        self.mel_image_size = mel_image_size\n",
    "        if hop_length is None:\n",
    "            self.hop_length = int(\n",
    "                self.signal_lenght * self.sample_rate / (self.mel_image_size - 1)\n",
    "            )\n",
    "        else:\n",
    "            self.hop_length = hop_length\n",
    "        self._melspectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "            power=2.0,\n",
    "            win_length=win_length,\n",
    "            n_fft=n_fft,\n",
    "            n_mels=n_mels,\n",
    "            sample_rate=sample_rate,\n",
    "            hop_length=self.hop_length,\n",
    "            f_min=min_frequency,\n",
    "            f_max=max_frequency,\n",
    "        ).to(self._device)\n",
    "\n",
    "    def msg(self, wave):\n",
    "        wave = torch.tensor(wave.reshape([1, -1]).astype(np.float32)).to(self._device)\n",
    "        mel_spec = self._melspectrogram(wave)[0].cpu().numpy()\n",
    "        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        if self.norm_mel_long:\n",
    "            mel_spec = (mel_spec - mel_spec.min()) / (mel_spec.max() - mel_spec.min())\n",
    "        mel_spec.astype(np.float32)\n",
    "        return mel_spec\n",
    "\n",
    "\n",
    "class Test_Kaggle:\n",
    "    def __init__(\n",
    "        self,\n",
    "        path,\n",
    "        df_coord_sites,\n",
    "        dict_birds,\n",
    "        n_fft,\n",
    "        sample_rate,\n",
    "        mel_image_size,\n",
    "        signal_lenght,\n",
    "        mel_provider,\n",
    "        norm_mel_short=True,\n",
    "        hop_length=None,\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        self.path = path\n",
    "        self._device = device\n",
    "        self.signal_lenght = signal_lenght\n",
    "        self.sample_rate = sample_rate\n",
    "        self.mel_image_size = mel_image_size\n",
    "        self.hop_length = int(\n",
    "            self.signal_lenght * self.sample_rate / (self.mel_image_size - 1)\n",
    "        )\n",
    "        self.norm_mel_short = norm_mel_short\n",
    "        self.mel_provider = mel_provider\n",
    "        self.n_fft = n_fft\n",
    "        self.df_coord_sites = df_coord_sites\n",
    "        self.dict_birds = dict_birds\n",
    "\n",
    "    def make_df(self):\n",
    "        path = self.path\n",
    "        list_files = []\n",
    "        for filename in os.listdir(path):\n",
    "            if filename.split(\".\")[-1] == \"ogg\":\n",
    "                list_files.append(filename)\n",
    "                call, srt = librosa.load(path + filename, sr=self.sample_rate)\n",
    "                duration = librosa.get_duration(\n",
    "                    call,\n",
    "                    sr=self.sample_rate,\n",
    "                    n_fft=self.n_fft,\n",
    "                    hop_length=int(\n",
    "                        self.signal_lenght\n",
    "                        * self.sample_rate\n",
    "                        / (self.mel_image_size - 1)\n",
    "                    ),\n",
    "                )\n",
    "        df = pd.DataFrame()\n",
    "        for filename in list_files:\n",
    "            df.loc[filename, \"filename\"] = filename\n",
    "            df.loc[filename, \"audio_id\"] = filename.split(\"_\")[0]\n",
    "            df.loc[filename, \"site\"] = filename.split(\"_\")[1]\n",
    "            df.loc[filename, \"date\"] = filename.split(\"_\")[2].split(\".\")[0]\n",
    "            df.loc[filename, \"duration\"] = duration\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y%m%d\")\n",
    "        df[\"month\"] = df[\"date\"].dt.month\n",
    "        df[\"year\"] = df[\"date\"].dt.year\n",
    "        df = df.merge(self.df_coord_sites, on=\"site\", how=\"left\")\n",
    "        df[\"sin_month\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
    "        df[\"cos_month\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
    "        df[\"sin_longitude\"] = np.sin(2 * np.pi * (df[\"longitude\"]) / 360)\n",
    "        df[\"cos_longitude\"] = np.cos(2 * np.pi * (df[\"longitude\"]) / 360)\n",
    "        df[\"norm_latitude\"] = (df[\"latitude\"] + 90) / 180\n",
    "        df[\"audio_id\"] = df[\"audio_id\"].astype(\"int\")\n",
    "        return df\n",
    "\n",
    "    def get_audio(self, file_path):\n",
    "        wave, sr = librosa.load(file_path, sr=self.sample_rate)\n",
    "        return wave\n",
    "\n",
    "    def make_prediction(self, df, model, thresh=0.5, predict=True, return_mels=False):\n",
    "        path = self.path\n",
    "        dict_row_id = {}\n",
    "        predictions = {}\n",
    "        for ix in df.index.tolist():\n",
    "            wave_name = df.loc[ix, \"filename\"]\n",
    "            audio_id = df.loc[ix, \"audio_id\"]\n",
    "            site = df.loc[ix, \"site\"]\n",
    "            wave = self.get_audio(path + wave_name)\n",
    "            mel_spec = self.mel_provider.msg(wave)\n",
    "            list_mels = []\n",
    "            for end_sec in range(\n",
    "                5, int(df.loc[ix, \"duration\"]) + 1, self.signal_lenght\n",
    "            ):\n",
    "                row_id = \"_\".join([str(audio_id), site, str(end_sec)])\n",
    "                start = int(\n",
    "                    ((end_sec - self.signal_lenght) * self.mel_image_size)\n",
    "                    / self.signal_lenght\n",
    "                )\n",
    "                mel_short = mel_spec[:, start : start + self.mel_image_size]\n",
    "\n",
    "                if self.norm_mel_short:\n",
    "                    mel_short = (\n",
    "                        (mel_short - mel_short.min())\n",
    "                        / (mel_short.max() - mel_short.min())\n",
    "                        * 255\n",
    "                    )\n",
    "                else:\n",
    "                    mel_short = mel_short * 255\n",
    "                if mel_short.shape != (self.mel_image_size, self.mel_image_size):\n",
    "                    mel_short = Image.fromarray(mel_short)\n",
    "                    mel_short = mel_short.resize(\n",
    "                        (self.mel_image_size, self.mel_image_size),\n",
    "                        Image.BICUBIC,\n",
    "                    )\n",
    "                    mel_short = np.array(mel_short)\n",
    "                mel_short = np.repeat(\n",
    "                    np.expand_dims(mel_short.astype(np.uint8), 2), 3, 2\n",
    "                )\n",
    "                mel_short[self.mel_image_size - 15 :, :20, 0] = (\n",
    "                    255 * df.loc[ix, \"sin_month\"]\n",
    "                )\n",
    "                mel_short[self.mel_image_size - 15 :, :20, 1] = 255\n",
    "                mel_short[self.mel_image_size - 15 :, :20, 2] = 0\n",
    "                mel_short[self.mel_image_size - 15 :, 20:40, 0] = 255\n",
    "                mel_short[self.mel_image_size - 15 :, 20:40, 1] = (\n",
    "                    255 * df.loc[ix, \"cos_month\"]\n",
    "                )\n",
    "                mel_short[self.mel_image_size - 15 :, 20:40, 2] = 0\n",
    "                mel_short[\n",
    "                    self.mel_image_size - 15 :,\n",
    "                    self.mel_image_size - 60 : self.mel_image_size - 40,\n",
    "                    0,\n",
    "                ] = (\n",
    "                    255 * df.loc[ix, \"sin_longitude\"]\n",
    "                )\n",
    "                mel_short[\n",
    "                    self.mel_image_size - 15 :,\n",
    "                    self.mel_image_size - 60 : self.mel_image_size - 40,\n",
    "                    1,\n",
    "                ] = 255\n",
    "                mel_short[\n",
    "                    self.mel_image_size - 15 :,\n",
    "                    self.mel_image_size - 60 : self.mel_image_size - 40,\n",
    "                    2,\n",
    "                ] = 255\n",
    "                mel_short[\n",
    "                    self.mel_image_size - 15 :,\n",
    "                    self.mel_image_size - 40 : self.mel_image_size - 20,\n",
    "                    0,\n",
    "                ] = 255\n",
    "                mel_short[\n",
    "                    self.mel_image_size - 15 :,\n",
    "                    self.mel_image_size - 40 : self.mel_image_size - 20,\n",
    "                    1,\n",
    "                ] = (\n",
    "                    255 * df.loc[ix, \"cos_longitude\"]\n",
    "                )\n",
    "                mel_short[\n",
    "                    self.mel_image_size - 15 :,\n",
    "                    self.mel_image_size - 40 : self.mel_image_size - 20,\n",
    "                    2,\n",
    "                ] = 255\n",
    "                mel_short[\n",
    "                    self.mel_image_size - 15 :, self.mel_image_size - 20 :, 0\n",
    "                ] = 255\n",
    "                mel_short[\n",
    "                    self.mel_image_size - 15 :, self.mel_image_size - 20 :, 1\n",
    "                ] = 255\n",
    "                mel_short[self.mel_image_size - 15 :, self.mel_image_size - 20 :, 2] = (\n",
    "                    255 * df.loc[ix, \"norm_latitude\"]\n",
    "                )\n",
    "                list_mels.append([row_id, mel_short])\n",
    "\n",
    "                if predict:\n",
    "                    mel_short = tf.expand_dims(mel_short, axis=0)\n",
    "                    pred = model.predict(mel_short)[0]\n",
    "                    dict_row_id[row_id] = wave_name\n",
    "                    predictions[row_id] = pred\n",
    "        predictions = pd.DataFrame(predictions).T\n",
    "        dict_row_id = pd.DataFrame(dict_row_id).T\n",
    "        pred_df = predictions.merge(dict_row_id, on=\"row_id\")\n",
    "        if predict:\n",
    "            return pred_df\n",
    "        if return_mels:\n",
    "            return mel_spec, list_mels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
